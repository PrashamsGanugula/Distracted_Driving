{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fafa413",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Notebook: 3-Live-Prediction.ipynb (Final Version with Video Display Fix)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode # Import the necessary library for embedding\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_DIR = \"D:/Distracted_Driving_Detection_Project\"\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"Model_Results\")\n",
    "MODEL_PATH = os.path.join(RESULTS_DIR, 'best_model.keras')\n",
    "\n",
    "CLASSES_LIST = [\"Normal_Driving\", \"Looking_Left\", \"Looking_Right\", \"Using_Phone\"]\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 64, 64\n",
    "SEQUENCE_LENGTH = 20\n",
    "\n",
    "# --- PREDICTION FUNCTIONS ---\n",
    "def frames_extraction(video_path):\n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_frames_window = max(int(video_frames_count / SEQUENCE_LENGTH), 1)\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "        success, frame = video_reader.read()\n",
    "        if not success: break\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        frames_list.append(resized_frame / 255.0)\n",
    "    video_reader.release()\n",
    "    return frames_list\n",
    "\n",
    "def predict_on_video(video_path):\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        return f\"Error: Model not found at {MODEL_PATH}\"\n",
    "    \n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    video_frames = frames_extraction(video_path)\n",
    "    \n",
    "    if len(video_frames) != SEQUENCE_LENGTH:\n",
    "        return f\"Error: The video is too short or could not be processed.\"\n",
    "\n",
    "    frames_for_prediction = np.expand_dims(video_frames, axis=0)\n",
    "    predictions = model.predict(frames_for_prediction)\n",
    "    predicted_class_name = CLASSES_LIST[np.argmax(predictions)]\n",
    "    confidence = np.max(predictions) * 100\n",
    "    \n",
    "    print(f\"âœ… PREDICTION: '{predicted_class_name}' ({confidence:.2f}%)\")\n",
    "    \n",
    "    # --- THIS BLOCK IS NOW CORRECTED TO EMBED THE VIDEO ---\n",
    "    # Read the video file in binary mode\n",
    "    mp4 = open(video_path,'rb').read()\n",
    "    # Encode it in base64 and create a data URL\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    \n",
    "    # Return an HTML object with the embedded video data\n",
    "    return HTML(f\"\"\"\n",
    "    <video width=400 controls>\n",
    "          <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\")\n",
    "    # --- END OF FIX ---\n",
    "\n",
    "# ==============================================================================\n",
    "# Your test video path\n",
    "# ==============================================================================\n",
    "test_video_path = \"D:/Distracted_Driving_Detection_Project/test_video.mp4\"\n",
    "\n",
    "if os.path.exists(test_video_path):\n",
    "    display(predict_on_video(test_video_path))\n",
    "else:\n",
    "    print(f\"Test video not found at: {test_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
